{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vgg16 import vgg16 as vgg_16\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imread, imshow\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from google.protobuf import json_format\n",
    "from imagenet_classes import class_names\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# It wrong follow thw paper you need to implement the model ad use back prop to image DAAAAAAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights ['conv1_1_W', 'conv1_1_b', 'conv1_2_W', 'conv1_2_b', 'conv2_1_W', 'conv2_1_b', 'conv2_2_W', 'conv2_2_b', 'conv3_1_W', 'conv3_1_b', 'conv3_2_W', 'conv3_2_b', 'conv3_3_W', 'conv3_3_b', 'conv4_1_W', 'conv4_1_b', 'conv4_2_W', 'conv4_2_b', 'conv4_3_W', 'conv4_3_b', 'conv5_1_W', 'conv5_1_b', 'conv5_2_W', 'conv5_2_b', 'conv5_3_W', 'conv5_3_b', 'fc6_W', 'fc6_b', 'fc7_W', 'fc7_b', 'fc8_W', 'fc8_b']\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    imgs = tf.placeholder(tf.float32,[1, 224, 224, 3])\n",
    "    vgg = vgg_16(imgs, 'vgg16_weights.npz', sess)\n",
    "    vgg_graph = sess.graph\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name:conv1_1  kernel:(3, 3, 3, 64)  \n",
      "name:conv1_2  kernel:(3, 3, 64, 64) \n",
      "name:conv2_1  kernel:(3, 3, 64, 128)\n",
      "name:conv2_2  kernel:(3, 3, 128, 128)\n",
      "name:conv3_1  kernel:(3, 3, 128, 256)\n",
      "name:conv3_2  kernel:(3, 3, 256, 256)\n",
      "name:conv3_3  kernel:(3, 3, 256, 256)\n",
      "name:conv4_1  kernel:(3, 3, 256, 512)\n",
      "name:conv4_2  kernel:(3, 3, 512, 512)\n",
      "name:conv4_3  kernel:(3, 3, 512, 512)\n",
      "name:conv5_1  kernel:(3, 3, 512, 512)\n",
      "name:conv5_2  kernel:(3, 3, 512, 512)\n",
      "name:conv5_3  kernel:(3, 3, 512, 512)\n",
      "name:fc1      kernel:(25088, 4096)  \n",
      "name:fc2      kernel:(4096, 4096)   \n",
      "name:fc3      kernel:(4096, 1000)   \n"
     ]
    }
   ],
   "source": [
    "ac_convs=list()\n",
    "for v in vgg_graph.get_collection(\"trainable_variables\"):\n",
    "    if \"biases\" not in v.name:\n",
    "        l_name = re.findall(r\".+(?=\\/)\", v.name)[0]\n",
    "        if l_name.startswith(\"conv\"):\n",
    "            ac_convs.append(vgg_graph.get_tensor_by_name(l_name + \":0\"))\n",
    "        print(\"name:{:8} kernel:{:15}\".format(l_name, str(v.shape)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = resize(imread(\"sh.jpg\"), [224, 224])\n",
    "style = resize(imread(\"salvador-dali-painting.jpg\"), [224, 224])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'conv3_3:0' shape=(1, 56, 56, 256) dtype=float32>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg.conv3_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content_loss(content_act, generated_act):\n",
    "    return(0.5*np.sum(np.square(content_act - generated_act)))\n",
    "\n",
    "def get_content_loss_gradient(content_act, generated_act):\n",
    "    grad = content_act - generated_act\n",
    "    grad[np.where(content_act<0)] = 0\n",
    "    return(grad)\n",
    "\n",
    "def get_gram(content_act):\n",
    "    assert(len(content_act.shape) == 3)\n",
    "    assert(content_act.shape[0] == content_act.shape[1])\n",
    "    gram = content_act.reshape((content_act.shape[0]*content_act.shape[1], content_act.shape[2]))\n",
    "    return(gram.T.dot(gram))\n",
    "\n",
    "def get_style_El(content_gram, generated_gram, no_of_filters, filter_size):\n",
    "    El = np.sum(np.square(generated_gram - content_gram))/(4*(no_of_filters**2)*(filter_size**2))\n",
    "    return(El)\n",
    "\n",
    "def get_style_El_gradient()\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(0)\n",
    "content_act = np.random.uniform(size=(10, 10)).astype(np.float32) - 0.5\n",
    "np.random.seed(1)\n",
    "generated_act = np.random.uniform(size=(10, 10)).astype(np.float32) - 0.5\n",
    "\n",
    "assert(np.sum((content_act - generated_act)**2)/2 == get_content_loss(content_act, generated_act))\n",
    "\n",
    "g = content_act[2,:] - generated_act[2, :]\n",
    "g[[2, 4, 6, 9]]=0\n",
    "assert(np.all(g==get_content_loss_gradient(content_act,generated_act)[2, :]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(0)\n",
    "content_act = np.random.uniform(size=(5, 5, 10)).astype(np.float32) - 0.5\n",
    "np.random.seed(1)\n",
    "generated_act = np.random.uniform(size=(5, 5, 10)).astype(np.float32) - 0.5\n",
    "\n",
    "\n",
    "g_content = get_gram(content_act)\n",
    "assert(np.abs(g_content[2,8] - np.sum(np.multiply(content_act[:,:,2].ravel(),content_act[:,:,8].ravel())))<1e-4)\n",
    "assert(np.abs(g_content[4,5] - np.sum(np.multiply(content_act[:,:,4].ravel(),content_act[:,:,5].ravel())))<1e-4)\n",
    "\n",
    "\n",
    "el_style = get_style_El(content_gram=get_gram(content_act), generated_gram=get_gram(generated_act), \n",
    "                        no_of_filters=content_act.shape[2], filter_size=content_act.shape[1]*content_act.shape[0])\n",
    "\n",
    "assert(el_style - np.sum(np.square(get_gram(content_act) - get_gram(generated_act)))/(4*(25**2)*100)<1e-4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = imread('Trumpfunny.jpg',  mode='RGB')\n",
    "img1 = resize(img1, (224, 224))\n",
    "\n",
    "prob = sess.run(vgg.probs, feed_dict={vgg.imgs: [img1]})[0]\n",
    "preds = (np.argsort(prob)[::-1])[0:5]\n",
    "for p in preds:\n",
    "    print (class_names[p], prob[p])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
